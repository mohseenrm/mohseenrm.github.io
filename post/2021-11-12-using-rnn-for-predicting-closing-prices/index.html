<html><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel=icon href=/images/favicon.svg><link rel=stylesheet href=/scss/global.min.f357d21dbbf537c4e8d7f3f760c674746a6982d871d25a27737d1dd68cfd5072.css><link rel=stylesheet href=/css/prism.css><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css?family=Merriweather&display=swap" rel=stylesheet><link href="https://fonts.googleapis.com/css2?family=Fira+Code:wght@300;400;500;600;700&display=swap" rel=stylesheet><link href="https://fonts.googleapis.com/css2?family=Nunito+Sans:ital,wght@0,200;0,300;0,400;0,600;0,700;0,800;0,900;1,200;1,300;1,400;1,600;1,700;1,800;1,900&display=swap" rel=stylesheet><link href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap" rel=stylesheet><link rel=stylesheet href=https://use.typekit.net/yka3uyp.css><title>Using RNN for Predicting Closing Prices | Mohseen</title><meta name=description content="Introduction Heyo there! with a lot of buzz going around machine learning and deep learning, I wanted to try out using a RNN (Recurrent neural network) model to see how well it can predict the closing price of a cryptocurrency. Machine learning models have gotten really good at modeling real world data, so I wanted to see how well it can do with predicting crypto movements after training it with historical data."><meta property="og:title" content="Using RNN for Predicting Closing Prices | Mohseen"><meta property="og:site_name" content="Mohseen"><meta property="og:description" content="Introduction Heyo there! with a lot of buzz going around machine learning and deep learning, I wanted to try out using a RNN (Recurrent neural network) model to see how well it can predict the closing price of a cryptocurrency. Machine learning models have gotten really good at modeling real world data, so I wanted to see how well it can do with predicting crypto movements after training it with historical data."><meta property="og:url" content="https://www.mohseen.dev/post/2021-11-12-using-rnn-for-predicting-closing-prices/"><meta property="og:type" content="website"><meta property="og:locale" content="en_US"><meta property="og:image" content><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="Using RNN for Predicting Closing Prices | Mohseen"><link rel=canonical href=https://www.mohseen.dev/post/2021-11-12-using-rnn-for-predicting-closing-prices/><meta name=twitter:description content="Introduction Heyo there! with a lot of buzz going around machine learning and deep learning, I wanted to try out using a RNN (Recurrent neural network) model to see how well it can predict the closing price of a cryptocurrency. Machine learning models have gotten really good at modeling real world data, so I wanted to see how well it can do with predicting crypto movements after training it with historical data."><meta name=twitter:image content><meta property="article:published_time" content="2021-11-12T12:09:02-08:00"><meta property="article:updated_time" content="2021-11-12T12:09:02-08:00"></head><body class=line-numbers><script src=/js/initColors.js></script><div class=layout-styled><section class=section><div class=nav-container><a class=logo-link href=/><div class=logo><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 767.42 894.15"><path id="first-m" fill="#1ee3cf" d="m301.64 485.72-85.91-166.86v122.29l83.17 167.52c9.36 18.77 36.24 18.64 45.4-.25l9-18.58zm282.07 44.29V798.7a25.27 25.27.0 1050.54.0V425.52zM625.08 9.15a31.28 31.28.0 00-50 8L385.9 393.31l32.2 62.5 155.1-320.6a5.54 5.54.0 0110.53 2.42v128.4l50.54-100.47V31.22a30.86 30.86.0 00-9.19-22.07zM60.33 16.91A31.29 31.29.0 0032.52.0h-1.24A31.26 31.26.0 000 31.22V798.7a25.3 25.3.0 0025.27 25.27h1a25.3 25.3.0 0025.27-25.27V133.97a5.55 5.55.0 0110.53-2.41l40.08 80.77V101.39c0-1 0-2 .06-3z"/><path id="second-m" fill="#d1d3d4" d="M767.42 101.42v767.46a25.27 25.27.0 01-25.27 25.27 25.26 25.26.0 01-25.25-25.27V207.82a5.55 5.55.0 00-10.55-2.41L477.4 678.6c-9.15 18.91-36 19-45.38.23L195.27 201.72a5.55 5.55.0 00-10.52 2.43v664.7a25.27 25.27.0 01-25.27 25.3h-1a25.27 25.27.0 01-25.27-25.27V101.42a31.26 31.26.0 0131.23-31.27h1.24a31.27 31.27.0 0127.8 17l254.77 494.87a6.3 6.3.0 0011.22.0l248.76-494.6a31.26 31.26.0 0127.93-17.27 31.26 31.26.0 0131.26 31.27z"/></svg></div><span class=header-hidden>Navigate back to the homepage</span></a><div class=nav-controls><button id=copyButton class=icon-wrapper><svg class="icon-image" width="24" height="20" viewBox="0 0 24 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path fillRule="evenodd" clipRule="evenodd" d="M2 5C2 3.34328 3.34328 2 5 2h9C15.6567 2 17 3.34328 17 5V9C17 10.6567 15.6567 12 14 12H10C9.44771 12 9 12.4477 9 13S9.44771 14 10 14h4C16.7613 14 19 11.7613 19 9V5C19 2.23872 16.7613.0 14 0H5C2.23872.0.0 2.23872.0 5V9C0 10.4938.656313 11.8361 1.6935 12.7509 2.10768 13.1163 2.73961 13.0767 3.10494 12.6625 3.47028 12.2483 3.43068 11.6164 3.0165 11.2511 2.39169 10.6999 2 9.89621 2 9V5zm5 6c0-1.65672 1.34328-3 3-3h4C14.5523 8 15 7.55228 15 7S14.5523 6 14 6H10C7.23872 6 5 8.23872 5 11v4C5 17.7613 7.23872 20 10 20h9C21.7613 20 24 17.7613 24 15V11C24 9.50621 23.3437 8.16393 22.3065 7.24906 21.8923 6.88372 21.2604 6.92332 20.8951 7.3375 20.5297 7.75168 20.5693 8.38361 20.9835 8.74894 21.6083 9.30007 22 10.1038 22 11v4C22 16.6567 20.6567 18 19 18H10C8.34328 18 7 16.6567 7 15V11z" fill="#000"/></svg><div id=toolTip class=tool-tip>copied</div><input id=copyText style=opacity:0 type=text class=tool-tip></button>
<button id=themeColorButton class=icon-wrapper><div id=sunRays class=sun-rays></div><div id=moonOrSun class=moon-or-sun></div><div id=moonMask class=moon-mask></div></button></div></div></section><script src=/js/toggleLogos.js></script><script src=/js/toggleColors.js></script><script src=/js/copyUrl.js></script><section class="section narrow"><section id=articleHero class="section narrow"><div class=article-hero><header class=article-header><h1 class=article-hero-heading>Using RNN for Predicting Closing Prices</h1><div class=article-hero-subtitle><div class=article-meta><a href=/authors/mohseen-mukaddam/ class=article-author-link><div class=article-author-avatar><img src=/images/mohseen-mukaddam.jpg></div><strong>Mohseen Mukaddam</strong>
<span class=hide-on-mobile>,&nbsp;</span></a>
<script src=/js/collapseAuthors.js></script>November 12, 2021
â€¢ 8 min read</div></div></header><div class=article-hero-image id=ArticleImage__Hero><picture>
<source srcset=/images/hero/Using-RNN-for-Predicting-Closing-Prices.jpg media="(min-width: 1280px) and (-webkit-min-device-pixel-ratio: 2), (min-width: 1280px) and (min-resolution: 192dpi)"><source srcset=/images/hero/Using-RNN-for-Predicting-Closing-Prices.jpg media="(min-width: 1280px)"><source srcset=/images/hero/Using-RNN-for-Predicting-Closing-Prices-tablet.jpg media="(min-width: 735px) and (-webkit-min-device-pixel-ratio: 2), (min-width: 735px) and (min-resolution: 192dpi)"><source srcset=/images/hero/Using-RNN-for-Predicting-Closing-Prices-tablet.jpg media="(min-width: 735px)"><source srcset=818x434.jpg media="(min-width: 540px) and (-webkit-min-device-pixel-ratio: 2), (min-width: 540px) and (min-resolution: 192dpi)"><source srcset=/images/hero/Using-RNN-for-Predicting-Closing-Prices-tablet.jpg media="(min-width: 540px)"><source srcset=/images/hero/Using-RNN-for-Predicting-Closing-Prices-mobile.jpg media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 2), (min-width: 320px) and (min-resolution: 192dpi)"><source srcset=/images/hero/Using-RNN-for-Predicting-Closing-Prices-mobile.jpg media="(min-width: 320px)"><source srcset=/images/hero/Using-RNN-for-Predicting-Closing-Prices-mobile.jpg media="(min-width: 0px) and (-webkit-min-device-pixel-ratio: 2), (min-width: 0px) and (min-resolution: 192dpi)"><source srcset=/images/hero/Using-RNN-for-Predicting-Closing-Prices-mobile.jpg media="(min-width: 0px)"><img src=/images/hero/Using-RNN-for-Predicting-Closing-Prices.jpg alt></picture></div></div></section><aside id=progressBar class=aside-container><div class=aside-align><div><div class=overlap-container></div></div></div><div class=progress-container tabindex={-1}><div class=track-line aria-hidden=true><div id=progressIndicator class=progress-line></div></div></div></aside><article id=articleContent class=post-content style=position:relative><h2 id=introduction>Introduction</h2><p>Heyo there! with a lot of buzz going around machine learning and deep learning, I wanted to try out using a RNN (<a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>Recurrent neural network</a>) model to see how well it can predict the closing price of a cryptocurrency. Machine learning models have gotten really good at modeling real world data, so I wanted to see how well it can do with predicting crypto movements after training it with historical data.</p><p>Machine learning models are evaluated based on many parameters like accuracy, precision and recall but the most importantly, how well can it do a task as an experienced human would perform. There was a <a href=https://jpm.pm-research.com/content/39/4/91>interesting study</a> that showed how monkeys can outperform fund managers when picking stocks over a one year period (while that might not apply to crypto) it&rsquo;s probably fair to say that we cannot reliably predict the closing price given just the historical data.</p><p><a href=https://www.analyticsvidhya.com/blog/2020/02/cnn-vs-rnn-vs-mlp-analyzing-3-types-of-neural-networks-in-deep-learning/>Deep learning models</a> have been applied to a lot of really difficult tasks like image classification, speech recognition, and even self driving cars. Each model is trained and retrained using a lot of data and of different types for more accurate results. For a sequence of data, RNN models are a good starting point since the output of the next node in a layer depends on the output of the previous ones. This helps it set weights and biases for the current layer and fine tunes it based on the training data provided. Since historical data is usually sequenced in time so it would be helpful to use it for trying to predict a value in the future given a window of 30-60 days.</p><p>There&rsquo;s also a <a href="https://www.youtube.com/watch?v=QIUxPv5PJOY">tutorial video</a> on using <a href="https://colab.research.google.com/?utm_source=scs-index">Google Colab</a> to build RNN models for predicting closing prices that goes over more details on why they&rsquo;re needed and how to hook them up all together.</p><h2 id=requirements>Requirements</h2><p>For setting up, you need <a href=https://jupyter.org/install>jupyter notebook</a> installed along with <a href=https://www.tensorflow.org/install>Tensorflow</a> and <a href=https://scikit-learn.org/stable/>scikit-learn</a> these libraries help you use the models, scalers and any other plotting utils that might be needed. After installing all the packages we can start with setting up the notebook.</p><h3 id=setting-up-notebook>Setting up notebook</h3><p>First lets import all the packages we might need.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> math
<span style=color:#f92672>import</span> numpy <span style=color:#f92672>as</span> np
<span style=color:#f92672>import</span> pandas <span style=color:#f92672>as</span> pd
<span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> MinMaxScaler
<span style=color:#f92672>from</span> keras.models <span style=color:#f92672>import</span> Sequential
<span style=color:#f92672>from</span> keras.layers <span style=color:#f92672>import</span> Dense, LSTM
<span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#f92672>as</span> plt
<span style=color:#f92672>import</span> matplotlib.dates <span style=color:#f92672>as</span> mdates
<span style=color:#f92672>import</span> requests
<span style=color:#f92672>from</span> io <span style=color:#f92672>import</span> StringIO
</code></pre></div><p>Next before we start defining the model, we want to setup parameters that can be used to train the model.</p><h3 id=using-hyperparameters-for-training-the-model>Using Hyperparameters for training the model</h3><p>Next, we need to setup model parameters or hyperparameters that allow you to fine tune the model and use different behavior when training it. Based on the dataset, some parameters like batch size, epochs have huge impact on how well the model fits to the training data. If it overfits, the training sample it might not be general enough to predict values outside of the training set, or if it&rsquo;s underfits the training sample it wouldn&rsquo;t be very accurate in predictions for training and test (validation) datasets.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e>### Model parameters</span>
num_of_days <span style=color:#f92672>=</span> <span style=color:#ae81ff>200</span>
batch_size <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
epochs <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
btc_symbol <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;BTC-USD&#39;</span>
</code></pre></div><p>Kaggle had a great article on <a href=https://www.kaggle.com/dansbecker/underfitting-and-overfitting>overfitting and underfitting</a> and how to identify if the model is behaving in a weird way.</p><h3 id=fetching-the-data>Fetching the data</h3><p>Now we can fetch the data needed for training and validating the model.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>base_url <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;https://query1.finance.yahoo.com/v7/finance/download&#39;</span>
user_agent_headers <span style=color:#f92672>=</span> {
    <span style=color:#e6db74>&#39;User-Agent&#39;</span>: <span style=color:#e6db74>&#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36&#39;</span>
}
params <span style=color:#f92672>=</span> {
    <span style=color:#e6db74>&#39;interval&#39;</span>: <span style=color:#e6db74>&#39;1d&#39;</span>,
    <span style=color:#e6db74>&#39;events&#39;</span>: <span style=color:#e6db74>&#39;history&#39;</span>,
    <span style=color:#e6db74>&#39;range&#39;</span>: <span style=color:#e6db74>&#39;5y&#39;</span>
}
response <span style=color:#f92672>=</span> requests<span style=color:#f92672>.</span>get(f<span style=color:#e6db74>&#39;{base_url}/{btc_symbol}&#39;</span>, params<span style=color:#f92672>=</span>params, headers<span style=color:#f92672>=</span>user_agent_headers)

<span style=color:#75715e># Historical data</span>
data <span style=color:#f92672>=</span> StringIO(response<span style=color:#f92672>.</span>text)

data <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_csv(data, index_col<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;Date&#39;</span>)<span style=color:#f92672>.</span>dropna()
data[<span style=color:#e6db74>&#39;Date&#39;</span>] <span style=color:#f92672>=</span> data<span style=color:#f92672>.</span>index
data
</code></pre></div><p>Once we have the information needed let&rsquo;s quickly double check if the data is in the right format.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>data<span style=color:#f92672>.</span>shape <span style=color:#75715e># (1822, 7) Number of records (1822), attributes like open, high, low, close, volume, etc (7).</span>
</code></pre></div><p>Awesome, now lets plot it and see what it looks like.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>plt<span style=color:#f92672>.</span>style<span style=color:#f92672>.</span>use(<span style=color:#e6db74>&#39;fivethirtyeight&#39;</span>)
<span style=color:#75715e># Plot closing price of ticker</span>
plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>30</span>, <span style=color:#ae81ff>16</span>))
plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#39;Close price history&#39;</span>)
plt<span style=color:#f92672>.</span>plot(data<span style=color:#f92672>.</span>index, data[<span style=color:#e6db74>&#39;Close&#39;</span>])
plt<span style=color:#f92672>.</span>xlabel(<span style=color:#e6db74>&#39;Date&#39;</span>, fontsize<span style=color:#f92672>=</span><span style=color:#ae81ff>18</span>)
plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#39;Close price USD&#39;</span>, fontsize<span style=color:#f92672>=</span><span style=color:#ae81ff>18</span>)
plt<span style=color:#f92672>.</span>gca()<span style=color:#f92672>.</span>xaxis<span style=color:#f92672>.</span>set_major_locator(mdates<span style=color:#f92672>.</span>YearLocator())
plt<span style=color:#f92672>.</span>xticks(rotation<span style=color:#f92672>=</span><span style=color:#ae81ff>45</span>)
plt<span style=color:#f92672>.</span>autoscale()
plt<span style=color:#f92672>.</span>show()
</code></pre></div><div class=Image__Medium><img src=/images/current_graph_btc.png alt="Current Graph BTC"></div><h3 id=split-data-into-training-and-validation-sets>Split data into training and validation sets</h3><p>Cool now let&rsquo;s split the data up in <span class=highlight-block>training</span> and <span class=highlight-block>validation</span> datasets. For this we will use 80% for training and 20% for validation.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># Prepare data</span>
dataset <span style=color:#f92672>=</span> data<span style=color:#f92672>.</span>filter([<span style=color:#e6db74>&#39;Close&#39;</span>])
<span style=color:#66d9ef>print</span>(dataset)
<span style=color:#75715e># convert to numpy array</span>
dataset <span style=color:#f92672>=</span> dataset<span style=color:#f92672>.</span>values

training_data_len <span style=color:#f92672>=</span> math<span style=color:#f92672>.</span>ceil(len(dataset) <span style=color:#f92672>*</span> <span style=color:#ae81ff>0.8</span>)
<span style=color:#66d9ef>print</span>(dataset)
<span style=color:#66d9ef>print</span>(training_data_len)
</code></pre></div><pre><code class=language-sample data-lang=sample>Date        Close
2016-09-06    610.435974
2016-09-07    614.544006
2016-09-08    626.315979
2016-09-09    622.861023
2016-09-10    623.508972
...                  ...
2021-09-01  48847.027344
2021-09-02  49327.722656
2021-09-03  50025.375000
2021-09-04  49944.625000
2021-09-06  51590.382813

[1822 rows x 1 columns]
[[  610.435974]
 [  614.544006]
 [  626.315979]
 ...
 [50025.375   ]
 [49944.625   ]
 [51590.382813]]
1458
</code></pre><h3 id=transform-training-data>Transform training data</h3><p>Before we split the data, we would need to scale it appropriately, if some attributes have a higher value than others it could skew the models towards higher value attributes. Example, if the price change is near 1-4% but the volume traded might be in thousand to millions, it could skew the model to prefer volume vs price change.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># Setup scaler</span>
scaler <span style=color:#f92672>=</span> MinMaxScaler(feature_range<span style=color:#f92672>=</span>(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>))
scaled_data <span style=color:#f92672>=</span> scaler<span style=color:#f92672>.</span>fit_transform(dataset)

scaled_data
</code></pre></div><pre><code class=language-sample data-lang=sample>array([[2.24743896e-04],
       [2.90046988e-04],
       [4.77179473e-04],
       ...,
       [7.85746452e-01],
       [7.84462814e-01],
       [8.10624508e-01]])
</code></pre><p>The <span class=highlight-block>MinMaxScaler</span> fits all the values between 0 and 1, so the highest value gets assigned 1 and the lowest gets assigned 0 and all other values in between get a value between 0 and 1.</p><p>Let&rsquo;s setup the training data for the model.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># Setup training data for model</span>
train_data <span style=color:#f92672>=</span> scaled_data[<span style=color:#ae81ff>0</span>:training_data_len, :]
<span style=color:#75715e># Split data in x_train and y_train</span>
x_train <span style=color:#f92672>=</span> []
y_train <span style=color:#f92672>=</span> []

<span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(num_of_days, len(train_data)):
    x_train<span style=color:#f92672>.</span>append(train_data[i<span style=color:#f92672>-</span>num_of_days:i, <span style=color:#ae81ff>0</span>])
    y_train<span style=color:#f92672>.</span>append(train_data[i, <span style=color:#ae81ff>0</span>])
</code></pre></div><p>In the training split <span class=highlight-block>x_train</span> is what is used as the initial input to the model so 0-199 days historical data is used to predict the <span class=highlight-block>y_train</span> value of day 200, and 1-200 is used to predict the value of day 201. You can play around with the number of days to see which one works better.</p><p>Sweet, now let&rsquo;s get the training data all prepped up for the model to use.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># convert x_train and y_train to numpy arrays</span>
x_train, y_train <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array(x_train), np<span style=color:#f92672>.</span>array(y_train)
<span style=color:#75715e># Reshape data</span>
x_train <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>reshape(x_train, (x_train<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>], x_train<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>1</span>], <span style=color:#ae81ff>1</span>))
x_train<span style=color:#f92672>.</span>shape
</code></pre></div><pre><code class=language-sample data-lang=sample>(1258, 200, 1)
</code></pre><h3 id=building-the-model>Building the model</h3><p>For building the RNN model layers we&rsquo;re using the an input LSTM (<a href=https://en.wikipedia.org/wiki/Long_short-term_memory>Long short-term memory</a>) a hidden LSTM, and dense layers for getting the outputs from previous layers.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># Build LSTM model</span>
model <span style=color:#f92672>=</span> Sequential()
model<span style=color:#f92672>.</span>add(LSTM(<span style=color:#ae81ff>50</span>, return_sequences<span style=color:#f92672>=</span>True, input_shape<span style=color:#f92672>=</span>(x_train<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>1</span>], <span style=color:#ae81ff>1</span>)))
model<span style=color:#f92672>.</span>add(LSTM(<span style=color:#ae81ff>50</span>, return_sequences<span style=color:#f92672>=</span>False))
model<span style=color:#f92672>.</span>add(Dense(<span style=color:#ae81ff>25</span>))
model<span style=color:#f92672>.</span>add(Dense(<span style=color:#ae81ff>1</span>))
</code></pre></div><p>After it&rsquo;s setup, we can now train the model using the training set.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># Train the model</span>
model<span style=color:#f92672>.</span>fit(x_train, y_train, batch_size<span style=color:#f92672>=</span>batch_size, epochs<span style=color:#f92672>=</span>epochs)
</code></pre></div><pre><code class=language-sample data-lang=sample>1258/1258 [==============================] - 60s 47ms/step - loss: 6.6969e-04
&lt;tensorflow.python.keras.callbacks.History at 0x7f0f13f0c1c0&gt;
</code></pre><h3 id=validation-predictions>Validation predictions</h3><p>The loss function should gradually decrease as the model learns from the training set. Now we can test the predictions from the validation set and how well it predicted values for the last 200 days.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># Create test data sets</span>
test_data <span style=color:#f92672>=</span> scaled_data[training_data_len <span style=color:#f92672>-</span> num_of_days: , :]
<span style=color:#75715e># Create scaled x_test, y_test</span>
x_test <span style=color:#f92672>=</span> []
y_test <span style=color:#f92672>=</span> dataset[training_data_len: , :]
<span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(num_of_days, len(test_data)):
    x_test<span style=color:#f92672>.</span>append(test_data[i<span style=color:#f92672>-</span>num_of_days: i, <span style=color:#ae81ff>0</span>])
</code></pre></div><p>The <span class=highlight-block>y_test</span> is not the actual closing price but a scaled result, so we would need to scale it back to the original values after the model outputs a predicted value.</p><p>Let&rsquo;s set up a test data set for the model.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># Convert test data to numpy array</span>
x_test <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array(x_test)
<span style=color:#75715e># Reshape data</span>
x_test <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>reshape(x_test, (x_test<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>], x_test<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>1</span>], <span style=color:#ae81ff>1</span>))
x_test<span style=color:#f92672>.</span>shape
</code></pre></div><pre><code class=language-sample data-lang=sample>(364, 200, 1)
</code></pre><p>And finally getting back the predictions from the model on the validation set.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># get model predictions</span>
predictions <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>predict(x_test)
predictions <span style=color:#f92672>=</span> scaler<span style=color:#f92672>.</span>inverse_transform(predictions)
</code></pre></div><p>Sweet, now we should calculate the total loss or mean squared error from the actual values.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># Calculate root mean squared error</span>
rmse <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>sqrt(np<span style=color:#f92672>.</span>mean(predictions <span style=color:#f92672>-</span> y_test) <span style=color:#f92672>**</span> <span style=color:#ae81ff>2</span>)
rmse
</code></pre></div><pre><code class=language-sample data-lang=sample>3078.505888980426
</code></pre><h3 id=plotting-results>Plotting results</h3><p>Ideally if the model predicted the exact value as expected the total loss would be 0. We can now plot the predicted values alongside the actual values of closing price for BTC.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># Plot the predicted values</span>
train <span style=color:#f92672>=</span> data[:training_data_len]
valid <span style=color:#f92672>=</span> data[training_data_len:]
valid[<span style=color:#e6db74>&#39;Predictions&#39;</span>] <span style=color:#f92672>=</span> predictions

plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>16</span>, <span style=color:#ae81ff>8</span>))
plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#39;Model&#39;</span>)
plt<span style=color:#f92672>.</span>xlabel(<span style=color:#e6db74>&#39;Date&#39;</span>, fontsize<span style=color:#f92672>=</span><span style=color:#ae81ff>18</span>)
plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#39;Close price USD&#39;</span>, fontsize<span style=color:#f92672>=</span><span style=color:#ae81ff>18</span>)
plt<span style=color:#f92672>.</span>plot(train[<span style=color:#e6db74>&#39;Close&#39;</span>])
plt<span style=color:#f92672>.</span>plot(valid[[<span style=color:#e6db74>&#39;Close&#39;</span>, <span style=color:#e6db74>&#39;Predictions&#39;</span>]])
plt<span style=color:#f92672>.</span>legend([<span style=color:#e6db74>&#39;Train&#39;</span>, <span style=color:#e6db74>&#39;Values&#39;</span>, <span style=color:#e6db74>&#39;Predictions&#39;</span>], loc<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;lower right&#39;</span>)
plt<span style=color:#f92672>.</span>show()
</code></pre></div><p><img src=/images/model_predictions_btc.png alt="Model Predictions for BTC"></p><h2 id=conclusion>Conclusion</h2><p>Not too far off for a really volatile crypto like BTC, but did find it interesting that initially the predicted values were very close to the actual values. But the errors started to compound as the model started to learn from the predicted values. Pretty impressive for using a simple RNN model from Tensorflow and Keras. It might be better to use more inputs like volume and other technical indicators that could maybe reduce errors in predicted values, but really cool to see in action.</p><p>That&rsquo;s all folks, hope this was helpful!</p><section id=subscriptionSection class="section narrow"><div class=subscription-container><div class=subscription-content><h3 class=subscription-heading>Join the email list and get notified about new content</h3><p class=subscription-text>Be the first to receive latest content with the ability to opt-out at
anytime.<br>We promise to not spam your inbox or share your email with any third
parties.</p><form id=subscriptionForm class=subscription-form action=https://formspree.io/f/mpzbwzjr method=post><input id=emailInput class=subscription-input placeholder=your@email.com name=email type=email required pattern="^[a-zA-Z0-9.!#$%&'*+/=?^_`{|}~-]+@[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)*$">
<button id=submitButton class=submit-button type=submit>
Subscribe</button><div class=subscription-error-message>The email you entered is not valid.</div></form></div></div></section><script src=/js/addFormStyles.js></script></article><section id=articleNext class="section nartrow"><h3 class=footer-next-heading>More articles from Mohseen</h3><div class=footer-spacer></div><div class=next-articles-grid numberofarticles={numberOfArticles}><div class=post-row><a href=/post/2023-10-06-unlocking-the-power-of-pure-functions/ class=article-link id=article-link-bigger><div><div class=image-container><img src=/images/hero/unlocking-the-power-of-pure-functions.preview.jpg class=article-image></div><div><h2 class=article-title>Unlocking the Power of Pure Functions</h2><p class=article-excerpt>Dive into the world of pure functions, a pillar of functional programming, and why they're essential for writing clean, maintainable code.</p><div class=article-metadata>October 6, 2023 Â· 3 min read</div></div></div></a><a href=/post/2023-10-06-automate-publishing-blogs-with-gpt-4/ class=article-link><div><div class=image-container><img src=/images/hero/automate-publishing-blogs-with-gpt-4.preview.jpg class=article-image></div><div><h2 class=article-title>Automate Publishing Blogs with GPT-4</h2><p class=article-excerpt>Reckless, yet intriguing use of GPT-4 to help write tech blogs.</p><div class=article-metadata>October 3, 2023 Â· 13 min read</div></div></div></a></div></div></section></section><script src=/js/progressBar.js></script><div class=footer-gradient></div><div class="section narrow"><div class=footer-hr></div><div class=footer-container><div class=footer-text>Â© 2023 Mohseen</div><div class=social-icon-outer><div class=social-icon-container><a href=https://facebook.com/momo3300><svg class="social-icon-image" width="7" height="14" viewBox="0 0 7 14" fill="none" xmlns="http://www.w3.org/2000/svg"><path fillRule="evenodd" clipRule="evenodd" d="M4.36849 7.36482H6.35279L6.64986 4.99457H4.36849V3.48124C4.36849 2.79501 4.55373 2.32731 5.5103 2.32731L6.73028 2.32673V.206821C6.51919.17804 5.79505.113525 4.95257.113525 3.19363.113525 1.98943 1.21807 1.98943 3.24662V4.99464H0V7.36488H1.98936V13.4469L4.36849 13.4468V7.36482z" fill="#73737d"/></svg></a><span class=hidden>https://facebook.com/momo3300</span>
<a href=https://github.com/mohseenrm><svg class="social-icon-image" width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg"><path fillRule="evenodd" clipRule="evenodd" d="M7 0C3.1325.0.0 3.21173.0 7.17706.0 10.3529 2.00375 13.0353 4.78625 13.9863 5.13625 14.0491 5.2675 13.8338 5.2675 13.6454 5.2675 13.4749 5.25875 12.9097 5.25875 12.3087 3.5 12.6406 3.045 11.8691 2.905 11.4653 2.82625 11.259 2.485 10.622 2.1875 10.4516 1.9425 10.317 1.5925 9.98508 2.17875 9.97611 2.73 9.96714 3.12375 10.4964 3.255 10.7118 3.885 11.7973 4.89125 11.4923 5.29375 11.3039 5.355 10.8374 5.53875 10.5234 5.74 10.3439 4.1825 10.1645 2.555 9.54549 2.555 6.80026 2.555 6.01976 2.82625 5.37382 3.2725 4.87143 3.2025 4.692 2.9575 3.95635 3.3425 2.96951 3.3425 2.96951 3.92875 2.78111 5.2675 3.70516 5.8275 3.54367 6.4225 3.46293 7.0175 3.46293S8.2075 3.54367 8.7675 3.70516C10.1063 2.77214 10.6925 2.96951 10.6925 2.96951 11.0775 3.95635 10.8325 4.692 10.7625 4.87143 11.2087 5.37382 11.48 6.01079 11.48 6.80026 11.48 9.55446 9.84375 10.1645 8.28625 10.3439 8.54 10.5682 8.75875 10.9988 8.75875 11.6717 8.75875 12.6316 8.75 13.4032 8.75 13.6454 8.75 13.8338 8.88125 14.0581 9.23125 13.9863 11.9963 13.0353 14 10.3439 14 7.17706 14 3.21173 10.8675.0 7 0z" fill="#73737d"/></svg></a><span class=hidden>https://github.com/mohseenrm</span>
<a href=https://instagram.com/mohseenrm><svg class="social-icon-image" width="13" height="13" viewBox="0 0 13 13" fill="none" xmlns="http://www.w3.org/2000/svg"><path fillRule="evenodd" clipRule="evenodd" d="M-305176e-10 3.97163C-305176e-10 1.77803 1.77824-244141e-9 3.97184-244141e-9H9.0281C11.2217-244141e-9 13 1.77802 13 3.97163V9.02788C13 11.2215 11.2217 12.9998 9.0281 12.9998H3.97184C1.77824 12.9998-305176e-10 11.2215-305176e-10 9.02789V3.97163zM3.97184 1.281C2.48585 1.281 1.28122 2.48564 1.28122 3.97163V9.02789C1.28122 10.5139 2.48585 11.7185 3.97184 11.7185H9.0281C10.5141 11.7185 11.7187 10.5139 11.7187 9.02788V3.97163C11.7187 2.48564 10.5141 1.281 9.0281 1.281H3.97184z" fill="#73737d"/><path fillRule="evenodd" clipRule="evenodd" d="M3.07483 6.55115C3.07483 4.64454 4.61242 3.09253 6.51702 3.09253 8.42162 3.09253 9.95921 4.64454 9.95921 6.55115S8.42162 10.0098 6.51702 10.0098C4.61242 10.0098 3.07483 8.45776 3.07483 6.55115zM6.51702 4.37378C5.32709 4.37378 4.35608 5.34508 4.35608 6.55115 4.35608 7.75722 5.32709 8.72853 6.51702 8.72853 7.70695 8.72853 8.67796 7.75722 8.67796 6.55115 8.67796 5.34508 7.70695 4.37378 6.51702 4.37378z" fill="#73737d"/><path fillRule="evenodd" clipRule="evenodd" d="M9.95062 3.87075C10.4035 3.87075 10.7706 3.50149 10.7706 3.04597 10.7706 2.59046 10.4035 2.22119 9.95062 2.22119 9.49776 2.22119 9.13065 2.59046 9.13065 3.04597 9.13065 3.50149 9.49776 3.87075 9.95062 3.87075z" fill="#73737d"/></svg></a><span class=hidden>https://instagram.com/mohseenrm</span>
<a href=https://www.linkedin.com/in/mohseenrm><svg class="social-icon-image" width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg"><path fillRule="evenodd" clipRule="evenodd" d="M3.59615 13.125H.871552V4.36523H3.59615V13.125zM2.24847 3.16406C1.81878 3.16406 1.44769 3.00781 1.13519 2.69531.822692 2.38281.666443 2.01171.666443 1.58203.666443 1.15234.822692.781248 1.13519.468749 1.44769.156249 1.81878.0 2.24847.0S3.04925.156249 3.36175.468749C3.67425.781248 3.8305 1.15234 3.8305 1.58203 3.8305 2.01171 3.67425 2.38281 3.36175 2.69531S2.67816 3.16406 2.24847 3.16406zM13.7915 13.125H11.0669V8.84765C11.0669 8.14452 11.0083 7.63671 10.8911 7.32421 10.6763 6.79687 10.2563 6.5332 9.63134 6.5332 9.00634 6.5332 8.56689 6.76757 8.31298 7.23632 8.11767 7.58788 8.02001 8.10546 8.02001 8.78905V13.125H5.32471V4.36523H7.93212V5.5664H7.96142C8.15673 5.17578 8.46923 4.85351 8.89892 4.59961 9.36767 4.28711 9.91454 4.13086 10.5395 4.13086 11.8091 4.13086 12.6977 4.53125 13.2055 5.33203 13.5962 5.97656 13.7915 6.97265 13.7915 8.3203V13.125z" fill="#73737d"/></svg></a><span class=hidden>https://www.linkedin.com/in/mohseenrm</span></div></div></div></div></div><script src=/js/prism.js></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');ga('create','G-WBJ981VMT6','auto');ga('send','pageview');}</script></body></html>